{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "c2620d5c", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Program 1: Bagging & Boosting\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\nX, y = load_iris(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nbag = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, random_state=42)\nbag.fit(X_train, y_train)\n\nboost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)\nboost.fit(X_train, y_train)\n\nbag_acc = accuracy_score(y_test, bag.predict(X_test))\nboost_acc = accuracy_score(y_test, boost.predict(X_test))\n\nprint(\"Bagging Accuracy:\", bag_acc)\nprint(\"Boosting Accuracy:\", boost_acc)\n", "outputs": []}, {"id": "34f8d04c", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Program 2: Bayesian Networks\nimport pandas as pd\nfrom pgmpy.models import DiscreteBayesianNetwork\nfrom pgmpy.estimators import MaximumLikelihoodEstimator\nfrom pgmpy.inference import VariableElimination\n\ndata = pd.DataFrame({\n    'Rain': ['Yes','Yes','No','No','Yes','No','Yes','No','No','Yes'],\n    'Traffic': ['High','High','Low','Low','Low','Low','High','Low','High','High'],\n    'Late': ['Yes','No','No','No','Yes','No','Yes','No','No','Yes']\n})\n\nmodel = DiscreteBayesianNetwork([('Rain', 'Traffic'), ('Traffic', 'Late')])\nmodel.fit(data, estimator=MaximumLikelihoodEstimator)\n\ninfer = VariableElimination(model)\nprob = infer.query(variables=['Late'], evidence={'Rain':'Yes'})\nprint(prob)\n", "outputs": []}, {"id": "7d6c8378", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Program 3: Find-S & Candidate Elimination\nimport pandas as pd\n\ndata = pd.DataFrame([\n    ['Sunny','Warm','Normal','Strong','Warm','Same','Yes'],\n    ['Sunny','Warm','High','Strong','Warm','Same','Yes'],\n    ['Rainy','Cold','High','Strong','Warm','Change','No'],\n    ['Sunny','Warm','High','Strong','Cool','Change','Yes']\n], columns=['Sky','AirTemp','Humidity','Wind','Water','Forecast','EnjoySport'])\n\nattributes = data.columns[:-1]\ntarget = data.columns[-1]\n\ndef find_s_algorithm(data):\n    specific_h = ['0'] * len(attributes)\n    for i in range(len(data)):\n        if data[target][i].lower() == 'yes':\n            if specific_h[0] == '0':\n                specific_h = data.iloc[i, :-1].tolist()\n            else:\n                for j in range(len(specific_h)):\n                    if specific_h[j] != data.iloc[i, j]:\n                        specific_h[j] = '?'\n    return specific_h\n\nspecific = find_s_algorithm(data)\nprint(\"Find-S Hypothesis:\", specific)\n", "outputs": []}, {"id": "459e2db2", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# Program 4: SOM Algorithm\nfrom minisom import MiniSom\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\n\nX = load_iris().data\nX = MinMaxScaler().fit_transform(X)\n\nsom = MiniSom(x=5, y=5, input_len=X.shape[1], sigma=1.0, learning_rate=0.5)\nsom.random_weights_init(X)\nsom.train_random(X, num_iteration=100)\n\nwin_map = np.array([som.winner(x) for x in X])\nprint(\"SOM neuron mappings (first 10):\", win_map[:10])\n", "outputs": []}]}